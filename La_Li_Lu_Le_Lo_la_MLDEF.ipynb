{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#To create a model that can predict the output variable for the next 5 minutes, in 30-second intervals, based on the input variables and relevant features from the dataset, you can follow these steps:\n",
    "\n",
    "    Preprocess the Data:\n",
    "        Handle any missing values in the dataset.\n",
    "        Split the dataset into training and testing sets.\n",
    "\n",
    "    Select Relevant Features:\n",
    "        Identify the input variables and any other features that you believe are relevant for predicting the output variable. Consider domain knowledge and feature importance analysis.\n",
    "        Extract the selected features from the dataset.\n",
    "\n",
    "    Train a Regression Model:\n",
    "        Choose a regression model suitable for your dataset, such as Linear Regression, Random Forest Regression, or Gradient Boosting Regression.\n",
    "        Split the training data into input features (X) and the target variable (y).\n",
    "        Fit the regression model on the training data.\n",
    "\n",
    "    Evaluate the Model:\n",
    "        Use the trained model to make predictions on the testing data.\n",
    "        Evaluate the model's performance by comparing the predicted values with the actual values of the output variable. Use evaluation metrics like mean squared error (MSE), mean absolute error (MAE), or R-squared.\n",
    "\n",
    "    Predict for Future Time Intervals:\n",
    "        Prepare the input features for the future time intervals (next 5 minutes, 30-second intervals) based on the operating conditions of the mill.\n",
    "        Use the trained model to predict the output variable for these future time intervals."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take what you need add what ever you want box\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from scipy.signal import correlate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import chardet\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# the ml zone\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here's a sample code template to guide you through the process:\n",
    "\n",
    "by chat gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Preprocess the Data\n",
    "\n",
    "# Handle missing values in the dataset\n",
    "# ...\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Select Relevant Features\n",
    "\n",
    "# Identify the relevant features\n",
    "# ...\n",
    "\n",
    "# Extract the selected features from the dataset\n",
    "X_train_selected = X_train[['feature1', 'feature2', ...]]\n",
    "X_test_selected = X_test[['feature1', 'feature2', ...]]\n",
    "\n",
    "# Step 3: Train a Regression Model\n",
    "\n",
    "# Choose a regression model and train it\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Step 4: Evaluate the Model\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = model.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = model.score(X_test_selected, y_test)\n",
    "\n",
    "# Step 5: Predict for Future Time Intervals\n",
    "\n",
    "# Prepare input features for future time intervals\n",
    "# ...\n",
    "\n",
    "# Use the trained model to predict the output variable for future time intervals\n",
    "predictions = model.predict(future_input_features)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this template, you need to replace 'feature1', 'feature2', ... with the names of the selected input features, and features, target, and future_input_features with the appropriate data from your dataset.\n",
    "\n",
    "You may need to experiment with different models, feature selections, and hyperparameters to find the best predictive performance for your specific problem.\n",
    "\n",
    "Remember to preprocess the data, handle missing values, and select features carefully to ensure the accuracy and reliability of the predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My try of modeling with the paspartu from above"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Preprocess the Data\n",
    "# ...\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_Semester[['feature1', 'feature2', ...]], df_Semester['target_variable'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Train XGBoost Regression Model\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Evaluate XGBoost Regression Model\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "\n",
    "# Step 4: Predict for Future Time Intervals\n",
    "# ...\n",
    "\n",
    "predictions_xgb = xgb_model.predict(future_input_features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please replace 'feature1', 'feature2', ... with the actual names of the selected input features, and 'target_variable' with the name of your output variable.\n",
    "\n",
    "Make sure to adjust the data variables (df_Semester, future_input_features) according to your DataFrame and the future time intervals you want to predict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Preprocess the Data\n",
    "# ...\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_Semester[['feature1', 'feature2', ...]], df_Semester['target_variable'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Train Random Forest Regression Model\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Evaluate Random Forest Regression Model\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "\n",
    "# Step 4: Predict for Future Time Intervals\n",
    "# ...\n",
    "\n",
    "predictions_rf = rf_model.predict(future_input_features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Preprocess the Data\n",
    "# ...\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_Semester[['feature1', 'feature2', ...]], df_Semester['target_variable'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Train Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Evaluate Linear Regression Model\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "\n",
    "# Step 4: Predict for Future Time Intervals\n",
    "# ...\n",
    "\n",
    "predictions_lr = lr_model.predict(future_input_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Preprocess the Data\n",
    "# ...\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_Semester[['feature1', 'feature2', ...]], df_Semester['target_variable'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Train Ridge Regression Model\n",
    "ridge_model = Ridge()\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Evaluate Ridge Regression Model\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "\n",
    "# Step 4: Predict for Future Time Intervals\n",
    "# ...\n",
    "\n",
    "predictions_ridge = ridge_model.predict(future_input_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Preprocess the Data\n",
    "# ...\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_Semester[['feature1', 'feature2', ...]], df_Semester['target_variable'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Train Lasso Regression Model\n",
    "lasso_model = Lasso()\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Evaluate Lasso Regression Model\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "\n",
    "# Step 4: Predict for Future Time Intervals\n",
    "# ...\n",
    "\n",
    "predictions_lasso = lasso_model.predict(future_input_features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ElasticNet Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Preprocess the Data\n",
    "# ...\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_Semester[['feature1', 'feature2', ...]], df_Semester['target_variable'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Train ElasticNet Regression Model\n",
    "elasticnet_model = ElasticNet()\n",
    "elasticnet_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Evaluate ElasticNet Regression Model\n",
    "y_pred_elasticnet = elasticnet_model.predict(X_test)\n",
    "mse_elasticnet = mean_squared_error(y_test, y_pred_elasticnet)\n",
    "\n",
    "# Step 4: Predict for Future Time Intervals\n",
    "# ...\n",
    "\n",
    "predictions_elasticnet = elasticnet_model.predict(future_input_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Preprocess the Data\n",
    "# ...\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_Semester[['feature1', 'feature2', ...]], df_Semester['target_variable'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Train Support Vector Regression Model\n",
    "svr_model = SVR()\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Evaluate Support Vector Regression Model\n",
    "y_pred_svr = svr_model.predict(X_test)\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "\n",
    "# Step 4: Predict for Future Time Intervals\n",
    "# ...\n",
    "\n",
    "predictions_svr = svr_model.predict(future_input_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_Semester[['feature1', 'feature2', ...]], df_Semester['target_variable'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Choose evaluation metric(s)\n",
    "# Example: Mean Squared Error (MSE) and R-squared (R2)\n",
    "metrics = {'MSE': mean_squared_error, 'R2': r2_score}\n",
    "\n",
    "# Step 3: Train and evaluate models\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Random Forest': RandomForestRegressor(),\n",
    "          'XGBoost': XGBRegressor()}\n",
    "\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    eval_scores = {}\n",
    "    for metric_name, metric_func in metrics.items():\n",
    "        score = metric_func(y_test, y_pred)\n",
    "        eval_scores[metric_name] = score\n",
    "\n",
    "    # Store the evaluation scores\n",
    "    results[model_name] = eval_scores\n",
    "\n",
    "# Step 4: Compare results\n",
    "for model_name, eval_scores in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    for metric_name, score in eval_scores.items():\n",
    "        print(f\"{metric_name}: {score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train and evaluate models\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Random Forest': RandomForestRegressor(),\n",
    "          'XGBoost': XGBRegressor()}\n",
    "\n",
    "results = {}\n",
    "for model_name, model in models.items(): \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    eval_scores = {}\n",
    "    for metric_name, metric_func in metrics.items():\n",
    "        score = metric_func(y_test, y_pred)\n",
    "        eval_scores[metric_name] = score\n",
    "\n",
    "    # Store the evaluation scores\n",
    "    results[model_name] = eval_scores\n",
    "    \n",
    "    # Plot predicted vs actual values\n",
    "    plt.figure()\n",
    "    plt.scatter(y_test, y_pred)\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=2)\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title(f'{model_name} - Predicted vs Actual')\n",
    "    plt.show()\n",
    "\n",
    "# Step 4: Compare results\n",
    "for model_name, eval_scores in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    for metric_name, score in eval_scores.items():\n",
    "        print(f\"{metric_name}: {score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated \n",
    "    mean_absolute_error, mean_squared_error, mean_absolute_percentage_error \n",
    "\n",
    "    for ploting we go from nominal to pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train and evaluate models\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Random Forest': RandomForestRegressor(),\n",
    "          'XGBoost': XGBRegressor()}\n",
    "\n",
    "results = {}\n",
    "for model_name, model in models.items(): \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    eval_scores = {}\n",
    "    for metric_name, metric_func in metrics.items():\n",
    "        score = metric_func(y_test, y_pred)\n",
    "        eval_scores[metric_name] = score\n",
    "\n",
    "    # Store the evaluation scores\n",
    "    results[model_name] = eval_scores\n",
    "    \n",
    "    # Plot predicted vs actual values\n",
    "    plt.figure()\n",
    "    plt.scatter(y_test, y_pred)\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=2)\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title(f'{model_name} - Predicted vs Actual')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot residuals\n",
    "    plt.figure()\n",
    "    residuals = y_test - y_pred\n",
    "    plt.scatter(y_pred, residuals)\n",
    "    plt.axhline(y=0, color='k', linestyle='--')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title(f'{model_name} - Residual Plot')\n",
    "    plt.show()\n",
    "\n",
    "# Step 4: Compare results\n",
    "for model_name, eval_scores in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    for metric_name, score in eval_scores.items():\n",
    "        print(f\"{metric_name}: {score}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Def to the rebel scams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_data(df, input_variables, output_variable):\n",
    "    X = df[input_variables]\n",
    "    y = df[output_variable]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def run_xgboost_regression(X_train, X_test, y_train, y_test):\n",
    "    model = xgb.XGBRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "    return mae, mse, mape\n",
    "\n",
    "def run_random_forest_regression(X_train, X_test, y_train, y_test):\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "    return mae, mse, mape\n",
    "\n",
    "def run_linear_regression(X_train, X_test, y_train, y_test):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "    return mae, mse, mape\n",
    "\n",
    "def run_ridge_regression(X_train, X_test, y_train, y_test):\n",
    "    model = Ridge()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "    return mae, mse, mape\n",
    "\n",
    "def run_lasso_regression(X_train, X_test, y_train, y_test):\n",
    "    model = Lasso()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "    return mae, mse, mape\n",
    "\n",
    "def run_elasticnet_regression(X_train, X_test, y_train, y_test):\n",
    "    model = ElasticNet()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "    return mae, mse, mape\n",
    "\n",
    "def run_svr(X_train, X_test, y_train, y_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    model = SVR()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions\n",
    "    mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "    return mae, mse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output variables\n",
    "input_variables = ['input_variable1', 'input_variable2', 'input_variable3']\n",
    "output_variable = 'output_variable'\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = split_data(df_Semester, input_variables, output_variable)\n",
    "\n",
    "# Run XGBoost regression\n",
    "xgboost_mae, xgboost_mse, xgboost_mape = run_xgboost_regression(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Run Random Forest regression\n",
    "rf_mae, rf_mse, rf_mape = run_random_forest_regression(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Run Linear regression\n",
    "linear_mae, linear_mse, linear_mape = run_linear_regression(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Run Ridge regression\n",
    "ridge_mae, ridge_mse, ridge_mape = run_ridge_regression(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Run Lasso regression\n",
    "lasso_mae, lasso_mse, lasso_mape = run_lasso_regression(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Run ElasticNet regression\n",
    "elasticnet_mae, elasticnet_mse, elasticnet_mape = run_elasticnet_regression(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Run SVR\n",
    "svr_mae, svr_mse, svr_mape = run_svr(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the evaluation metrics for each algorithm\n",
    "print(\"XGBoost Regression:\")\n",
    "print(\"MAE:\", xgboost_mae)\n",
    "print(\"MSE:\", xgboost_mse)\n",
    "print(\"MAPE:\", xgboost_mape)\n",
    "print()\n",
    "\n",
    "print(\"Random Forest Regression:\")\n",
    "print(\"MAE:\", rf_mae)\n",
    "print(\"MSE:\", rf_mse)\n",
    "print(\"MAPE:\", rf_mape)\n",
    "print()\n",
    "\n",
    "print(\"Linear Regression:\")\n",
    "print(\"MAE:\", linear_mae)\n",
    "print(\"MSE:\", linear_mse)\n",
    "print(\"MAPE:\", linear_mape)\n",
    "print()\n",
    "\n",
    "print(\"Ridge Regression:\")\n",
    "print(\"MAE:\", ridge_mae)\n",
    "print(\"MSE:\", ridge_mse)\n",
    "print(\"MAPE:\", ridge_mape)\n",
    "print()\n",
    "\n",
    "print(\"Lasso Regression:\")\n",
    "print(\"MAE:\", lasso_mae)\n",
    "print(\"MSE:\", lasso_mse)\n",
    "print(\"MAPE:\", lasso_mape)\n",
    "print()\n",
    "\n",
    "print(\"ElasticNet Regression:\")\n",
    "print(\"MAE:\", elasticnet_mae)\n",
    "print(\"MSE:\", elasticnet_mse)\n",
    "print(\"MAPE:\", elasticnet_mape)\n",
    "print()\n",
    "\n",
    "print(\"Support Vector Regression:\")\n",
    "print(\"MAE:\", svr_mae)\n",
    "print(\"MSE:\", svr_mse)\n",
    "print(\"MAPE:\", svr_mape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression_results(algorithm_names, mae_values, mse_values, mape_values):\n",
    "    # Plot Mean Absolute Error (MAE)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(algorithm_names, mae_values)\n",
    "    plt.xlabel('Algorithm')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('Mean Absolute Error (MAE) Comparison')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Mean Squared Error (MSE)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(algorithm_names, mse_values)\n",
    "    plt.xlabel('Algorithm')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('Mean Squared Error (MSE) Comparison')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Mean Absolute Percentage Error (MAPE)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(algorithm_names, mape_values)\n",
    "    plt.xlabel('Algorithm')\n",
    "    plt.ylabel('MAPE')\n",
    "    plt.title('Mean Absolute Percentage Error (MAPE) Comparison')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
